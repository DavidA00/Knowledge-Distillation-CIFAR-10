{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Here we combine the 3 distilled models to get a performance comaprable to the teacher."
      ],
      "metadata": {
        "id": "oUEXpnKfSsEO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Gj6dLyyxuTY",
        "outputId": "ee9f827e-999e-4965-c1bd-c898da9c890e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras.utils\n",
            "  Downloading keras-utils-1.0.13.tar.gz (2.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from keras.utils) (2.15.0)\n",
            "Building wheels for collected packages: keras.utils\n",
            "  Building wheel for keras.utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras.utils: filename=keras_utils-1.0.13-py3-none-any.whl size=2631 sha256=84798b58706b021b03c8b6c027fd99a1dd85e2d4c7dc32541d550fbb6f7d5a90\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/c0/b3/0c332de4fd71f3733ea6d61697464b7ae4b2b5ff0300e6ca7a\n",
            "Successfully built keras.utils\n",
            "Installing collected packages: keras.utils\n",
            "Successfully installed keras.utils-1.0.13\n"
          ]
        }
      ],
      "source": [
        "!pip install keras.utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVDoHT42xwvW",
        "outputId": "4db95f51-d3a4-4320-bfe4-cc16523c7a84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ojZDgRfxyo8",
        "outputId": "9840ddf8-3088-4aeb-cd54-76825a489c8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting keras\n",
            "  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Collecting namex (from keras)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Collecting optree (from keras)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Installing collected packages: namex, optree, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.3.3 namex-0.0.8 optree-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WqUMHaI7wUZb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras import datasets, layers, models\n",
        "from keras import regularizers\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyrAK0X9xo3V",
        "outputId": "4cc6ad64-9abc-47b3-ff83-d81e48b1ecdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zfsdcfscxh48"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "num_classes = 10\n",
        "train_images = train_images.astype('float32')\n",
        "test_images = test_images.astype('float32')\n",
        "train_images = train_images / 255\n",
        "test_images = test_images / 255\n",
        "num_classes = 10\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "train_images = np.reshape(train_images, (-1, 32, 32, 3))\n",
        "test_images = np.reshape(test_images, (-1, 32, 32, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ThLr6BMTx9M4"
      },
      "outputs": [],
      "source": [
        "teacher = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(32, 32, 3)),\n",
        "        layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        layers.Dropout(0.5),\n",
        "\n",
        "        layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        layers.Dropout(0.5),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "\n",
        "        layers.Dropout(0.5),\n",
        "\n",
        "        layers.Dense(num_classes),\n",
        "    ],\n",
        "    name=\"teacher\",\n",
        ")\n",
        "\n",
        "\n",
        "class Distiller_new(keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super().__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.2,\n",
        "        temperature=3,\n",
        "    ):\n",
        "        \"\"\"Configure the distiller.\n",
        "\n",
        "        Args:\n",
        "            optimizer: Keras optimizer for the student weights\n",
        "\n",
        "            metrics: Keras metrics for evaluation\n",
        "\n",
        "            student_loss_fn: Loss function of difference between student\n",
        "                predictions and ground-truth\n",
        "\n",
        "            distillation_loss_fn: Loss function of difference between soft\n",
        "                student predictions and soft teacher predictions\n",
        "\n",
        "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
        "\n",
        "            temperature: Temperature for softening probability distributions.\n",
        "                Larger temperature gives softer distributions.\n",
        "        \"\"\"\n",
        "        super().compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def compute_loss(\n",
        "        self, x=None, y=None, y_pred=None, sample_weight=None, allow_empty=False\n",
        "    ):\n",
        "        teacher_pred = self.teacher(x, training=False)\n",
        "        student_loss = self.student_loss_fn(y, y_pred)\n",
        "\n",
        "        distillation_loss = self.distillation_loss_fn(\n",
        "            ops.softmax(teacher_pred / self.temperature, axis=1),\n",
        "            ops.softmax(y_pred / self.temperature, axis=1),\n",
        "        ) * (self.temperature**2)\n",
        "\n",
        "        loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "        return loss\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self.student(x, training=True)\n",
        "\n",
        "            loss = self.compute_loss(x, y, y_pred)\n",
        "\n",
        "        gradients = tape.gradient(loss, self.student.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.student.trainable_variables))\n",
        "\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        x, y = data\n",
        "        y_pred = self.student(x, training=False)\n",
        "\n",
        "        loss = self.compute_loss(x, y, y_pred)\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "student = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(32, 32, 3)),\n",
        "        layers.Conv2D(8, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(8, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(16, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(16, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "\n",
        "        layers.Dense(num_classes),\n",
        "    ],\n",
        "    name=\"student\",\n",
        ")\n",
        "\n",
        "\n",
        "student_scratch = keras.models.clone_model(student)\n",
        "student_A = keras.models.clone_model(student)\n",
        "student_B = keras.models.clone_model(student)\n",
        "student_C = keras.models.clone_model(student)\n",
        "\n",
        "\n",
        "teacher.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uqv0shECwzo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d0fe97-8764-44d0-a2f4-45dd9eec7d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 62 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "A = Distiller_new(student= student_A, teacher=teacher)\n",
        "\n",
        "A.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0.2,\n",
        "    temperature=5,\n",
        ")\n",
        "\n",
        "\n",
        "B = Distiller_new(student= student_B, teacher=teacher)\n",
        "\n",
        "B.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0.2,\n",
        "    temperature=5,\n",
        ")\n",
        "\n",
        "C = Distiller_new(student= student_C, teacher=teacher)\n",
        "\n",
        "C.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0.2,\n",
        "    temperature=5,\n",
        ")\n",
        "\n",
        "teacher.load_weights(\"teacher.weights.h5\")\n",
        "A.load_weights(\"distilled_student_1.weights.h5\")\n",
        "B.load_weights(\"distilled_student_2.weights.h5\")\n",
        "C.load_weights(\"distilled_student_3.weights.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9YxPk3N038K",
        "outputId": "6e900ef7-3e31-4687-b82d-095750a34cf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4044 - sparse_categorical_accuracy: 0.8701\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4072171747684479, 0.868399977684021]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#we verify that its loaded well\n",
        "teacher.evaluate(test_images, test_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.evaluate(test_images, test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNqjWUhUhgAL",
        "outputId": "a88c19cb-6b29-4848-edcf-b8df7fa71d27"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py:578: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
            "```\n",
            "for metric in self.metrics:\n",
            "    metric.update_state(y, y_pred)\n",
            "```\n",
            "\n",
            "  return self._compiled_metrics_update_state(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - sparse_categorical_accuracy: 0.7892 - loss: -0.0818\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.07023735344409943,\n",
              " -0.07023735344409943,\n",
              " 0.7854999899864197,\n",
              " 0.7854999899864197]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B.evaluate(test_images, test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JxR1X9-hjwr",
        "outputId": "7d4d51ff-d191-4366-f72d-e248b4dbaba7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - sparse_categorical_accuracy: 0.7911 - loss: 0.0411\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.045466408133506775,\n",
              " 0.045466408133506775,\n",
              " 0.7900000214576721,\n",
              " 0.7900000214576721]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C.evaluate(test_images, test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4vdDBBXiZuF",
        "outputId": "2f72866a-5243-4e39-b2e9-6c76cdffea07"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py:578: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
            "```\n",
            "for metric in self.metrics:\n",
            "    metric.update_state(y, y_pred)\n",
            "```\n",
            "\n",
            "  return self._compiled_metrics_update_state(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - sparse_categorical_accuracy: 0.7957 - loss: -0.0720\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.07121355086565018,\n",
              " -0.07121355086565018,\n",
              " 0.7986999750137329,\n",
              " 0.7986999750137329]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# To get class labels from predictions\n",
        "#predicted_labels = tf.argmax(predictions, axis=1)\n",
        "logitsA = A.student.predict(test_images)\n",
        "logitsB = B.student.predict(test_images)\n",
        "logitsC = C.student.predict(test_images)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4h4HX7PmipZf",
        "outputId": "2920e3d1-fa29-4fbe-ff76-4eef3d3e7f4d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_logits = (logitsA + logitsB + logitsC) / 3.0\n",
        "\n",
        "average_predicted_labels = tf.argmax(average_logits, axis=1)\n",
        "predicted_A = np.array(tf.argmax(logitsA, axis=1))\n",
        "predicted_B = np.array(tf.argmax(logitsB, axis=1))\n",
        "predicted_C = np.array(tf.argmax(logitsC, axis=1))\n",
        "\n"
      ],
      "metadata": {
        "id": "ApweXpeFoFGF"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = np.array([test_labels[i][0] for i in range(len(test_labels))])\n",
        "average_predicted_labels = np.array(average_predicted_labels)"
      ],
      "metadata": {
        "id": "ren47pyNp9VZ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ6L5c5OrNbV",
        "outputId": "b7065da3-0e9d-4304-d5e6-083a5ef7e582"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 8, 8, 0, 6, 6, 1, 6, 3, 1], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_predicted_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqSYmWOmrfCM",
        "outputId": "6a69975a-0860-4db6-a751-ce30fd4c5375"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 8, 8, 0, 6, 6, 1, 6, 3, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_accuracy(y_true, y_pred):\n",
        "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "FijjtS4JqMWS"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_accuracy(test_labels, predicted_A)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eMlgMgYqrI_",
        "outputId": "aeeac080-4324-4220-9391-ede1a6acd92b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7855"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_accuracy(test_labels, predicted_B)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g7uRGqRsB3r",
        "outputId": "abcdd32f-f2e8-4b8c-deb3-76ccfaa08044"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.79"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_accuracy(test_labels, predicted_C)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G620Xa42sFsL",
        "outputId": "266fc8f7-27c4-4c78-97ad-803df865e20e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7987"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_accuracy(test_labels, average_predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLMBuMblsINa",
        "outputId": "02387f64-c85a-4acb-cb4a-7ea9087a7564"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8226"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_pred = np.array(tf.argmax(teacher.predict(test_images), axis =1))\n",
        "find_accuracy(test_labels, teacher_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n89-IakwxSim",
        "outputId": "b4a32c00-c6c1-4cd3-c381-ecf2a983b47f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8684"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scratchA = keras.models.clone_model(student)\n",
        "scratchB = keras.models.clone_model(student)\n",
        "scratchC = keras.models.clone_model(student)\n",
        "\n",
        "\n",
        "\n",
        "scratchA.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "scratchB.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "scratchC.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "\n",
        "scratchA.load_weights(\"nondistilled_student_1.weights.h5\")\n",
        "scratchB.load_weights(\"nondistilled_student_2.weights.h5\")\n",
        "scratchC.load_weights(\"nondistilled_student_3.weights.h5\")\n",
        "\n",
        "scratchA_l = scratchA.predict(test_images)\n",
        "scratchB_l = scratchB.predict(test_images)\n",
        "scratchC_l = scratchC.predict(test_images)\n",
        "\n",
        "\n",
        "average_scratch = (scratchA_l + scratchB_l + scratchC_l) / 3.0\n",
        "\n",
        "average_scratch_predicted_labels = np.array(tf.argmax(average_scratch, axis=1))\n",
        "\n",
        "\n",
        "find_accuracy(test_labels, average_scratch_predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRLVqKqAxavR",
        "outputId": "123a6bfa-a510-403a-8a8c-c2d1037f706c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 62 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7928"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}